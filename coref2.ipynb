{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import wikiapi\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "import requests\n",
    "from string import punctuation\n",
    "from lxml import html\n",
    "import random\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Coreftrain:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.docs = pd.read_csv('coref/Documents.txt', delimiter='\\t')\n",
    "        self.train_noun = pd.DataFrame(columns=['docid', 'start_ref', 'cor', 'incor'])\n",
    "        self.gold_noun =  pd.DataFrame(columns=['docid', 'start_ref', 'refs'])\n",
    "        self.no_gold_noun =  pd.DataFrame(columns=['docid', 'start_ref', 'refs'])\n",
    "        self.train_ne = pd.DataFrame(columns=['docid', 'start_ref', 'cor', 'incor'])\n",
    "        self.gold_ne =  pd.DataFrame(columns=['docid', 'start_ref', 'refs'])\n",
    "        self.no_gold_ne =  pd.DataFrame(columns=['docid', 'start_ref', 'refs'])\n",
    "        self.train_pron = pd.DataFrame(columns=['docid', 'start_ref', 'cor', 'incor'])\n",
    "        self.gold_pron =  pd.DataFrame(columns=['docid', 'start_ref', 'refs'])\n",
    "        self.no_gold_pron =  pd.DataFrame(columns=['docid', 'start_ref', 'refs'])\n",
    "        self.answers_noun = pd.DataFrame() # hold answers for training sets. separtatedby type. 9 total.\n",
    "        self.answers_ne = pd.DataFrame()\n",
    "        self.answers_pron = pd.DataFrame()\n",
    "        self.train_var_noun = pd.DataFrame()#training data\n",
    "        self.train_var_ne = pd.DataFrame()\n",
    "        self.train_var_pron = pd.DataFrame()\n",
    "        self.gold_var_noun = pd.DataFrame()#start vars for nouns\n",
    "        self.no_gold_var_noun = pd.DataFrame()\n",
    "        self.gold_var_ne = pd.DataFrame() #start vars for NEs\n",
    "        self.no_gold_var_ne = pd.DataFrame()\n",
    "        self.gold_var_pron = pd.DataFrame()#start vars for pronouns\n",
    "        self.no_gold_var_pron = pd.DataFrame()\n",
    "        self.idstr_noun = pd.DataFrame() # holds ids for merge reference.\n",
    "        self.idstr_ne = pd.DataFrame()\n",
    "        self.idstr_pron = pd.DataFrame()\n",
    "        self.ids_ne_gold = pd.DataFrame()# ne ids\n",
    "        self.ids_ne_nogold = pd.DataFrame()\n",
    "        self.ids_noun_gold = pd.DataFrame()# ne noun\n",
    "        self.ids_noun_nogold = pd.DataFrame()\n",
    "        self.ids_pron_gold = pd.DataFrame()# ne pron\n",
    "        self.ids_pron_nogold = pd.DataFrame()\n",
    "        \n",
    "    \n",
    "        #merge functions from previous doc. Was decided that corefsetup already to large, hence the repetition.\n",
    "    \n",
    "    def prepdf(self):\n",
    "        '''\n",
    "        Specifc to the structure of rucoref data. Creates table with doc ids and names.\n",
    "        '''          \n",
    "        self.newdf = pd.DataFrame(columns=['docid', 'docname'])\n",
    "        for path in self.docs['path']:\n",
    "            name = path.split('/')[1]\n",
    "            did = self.docs.loc[self.docs.path.values == path, 'doc_id'].values[0]\n",
    "            self.newdf = self.newdf.append(pd.Series([did, name], index=['docid', 'docname']), ignore_index=True)\n",
    "        return self.newdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def old_morph(self, headmen, head_pos):\n",
    "        '''\n",
    "        gathers morphological info from head mention.\n",
    "        '''\n",
    "        leng = len(headmen['morph'].values[0].split('|'))\n",
    "        if leng == 4:\n",
    "            ment_anim = headmen['morph'].values[0].split('|')[0].replace('Animacy=', '').split(',')\n",
    "            ment_case = headmen['morph'].values[0].split('|')[1].replace('Case=', '') #only one possible value.\n",
    "            ment_gen = headmen['morph'].values[0].split('|')[2].replace('Gender=', '').split(',')\n",
    "            ment_num = headmen['morph'].values[0].split('|')[3].replace('Number=', '').split(',')\n",
    "        elif leng == 3:\n",
    "            ment_anim = None\n",
    "            ment_case = headmen['morph'].values[0].split('|')[0].replace('Case=', '') #only one possible value.\n",
    "            ment_gen = headmen['morph'].values[0].split('|')[1].replace('Gender=', '').split(',')\n",
    "            ment_num = headmen['morph'].values[0].split('|')[2].replace('Number=', '').split(',')\n",
    "        else:\n",
    "            ment_anim = None\n",
    "            ment_case = None\n",
    "            ment_gen = None\n",
    "            ment_num = None\n",
    "        return ment_anim, ment_case, ment_gen, ment_num\n",
    "    \n",
    "    \n",
    "    def new_morph(self, new_anim, new_gen, new_num, ment_anim, ment_gen, ment_num, mer_men):\n",
    "        '''\n",
    "        combines morphological features of mentions with head mention.\n",
    "        '''\n",
    "        if not ment_anim == None:\n",
    "            if len(mer_men['morph'].values[0].split('|')) == 4:\n",
    "                mer_anim = mer_men['morph'].values[0].split('|')[0].replace('Animacy=', '').split(', ')\n",
    "                mer_gen = mer_men['morph'].values[0].split('|')[2].replace('Gender=', '').split(', ')\n",
    "                mer_num = mer_men['morph'].values[0].split('|')[3].replace('Number=', '').split(', ')\n",
    "                for mer_a in mer_anim:\n",
    "                    if mer_a not in ment_anim: #merging morphological features, if different.\n",
    "                        new_anim.append(mer_a)\n",
    "                for mer_g in mer_gen:\n",
    "                    if mer_g not in ment_gen:\n",
    "                        new_gen.append(mer_g)\n",
    "                for mer_n in mer_num:\n",
    "                    if mer_n not in ment_num:\n",
    "                        new_num.append(mer_n)\n",
    "                no_merge = False\n",
    "            else:\n",
    "                no_merge = True\n",
    "        elif not ment_gen == None:\n",
    "            mer_gen = mer_men['morph'].values[0].split('|')[1].replace('Gender=', '').split(', ')\n",
    "            mer_num = mer_men['morph'].values[0].split('|')[2].replace('Number=', '').split(', ')\n",
    "            new_anim = None\n",
    "            for mer_g in mer_gen:\n",
    "                if mer_g not in ment_gen:\n",
    "                    new_gen.append(mer_g)\n",
    "            for mer_n in mer_num:\n",
    "                if mer_n not in ment_num:\n",
    "                    new_num.append(mer_n)\n",
    "            no_merge = False\n",
    "        else:\n",
    "            new_anim = None\n",
    "            new_gen = None\n",
    "            new_num = None\n",
    "            no_merge = True\n",
    "        return new_anim, new_gen, new_num, no_merge\n",
    "          \n",
    "\n",
    "# merge types\n",
    "        \n",
    "   \n",
    "    def morph_merge(self, headmen, merges, mens):\n",
    "        '''\n",
    "        merges morphology of mentions to head mention.\n",
    "        '''\n",
    "        head_pos = headmen['udpos']\n",
    "        ment_anim, ment_case, ment_gen, ment_num = self.old_morph(headmen, head_pos) #creates list of all morph features of head mention.\n",
    "        new_anim = []\n",
    "        new_gen = []\n",
    "        new_num = []\n",
    "        if not ment_anim == None:\n",
    "            new_anim.extend(ment_anim)\n",
    "        elif not ment_case == None:\n",
    "            new_gen.extend(ment_gen)\n",
    "            new_num.extend(ment_num)\n",
    "        for mer in merges:\n",
    "            mer_men = mens[mens['shift'] == mer]\n",
    "            new_anim, new_gen, new_num, no_merge = self.new_morph(new_anim, new_gen, new_num, ment_anim, ment_gen, ment_num, mer_men)\n",
    "        if not new_anim == None and no_merge == False:\n",
    "            new_anim = \", \".join(list(set(new_anim))) #remove repeating features.\n",
    "            new_gen = \", \".join(list(set(new_gen)))\n",
    "            new_num = \", \".join(list(set(new_num)))\n",
    "            new_mor = 'Animacy={0}|Case={1}|Gender={2}|Number={3}'.format(new_anim, ment_case, new_gen, new_num)\n",
    "        elif no_merge == False and not new_gen == None:\n",
    "            new_gen = \", \".join(list(set(new_gen)))\n",
    "            new_num = \", \".join(list(set(new_num)))\n",
    "            new_mor = 'Case={0}|Gender={1}|Number={2}'.format(ment_case, new_gen, new_num)\n",
    "        else:\n",
    "            new_mor = headmen['morph'].values[0]\n",
    "        return new_mor   \n",
    "    \n",
    "    \n",
    "    def sid_merge(self, headmen, headmen_id, merges, mens):\n",
    "        '''\n",
    "        merges sentence id info, for later calculation of distances, as program chooses closest distance\n",
    "        when considering sentence range. Creates clust_head category for referencing back to head in order to\n",
    "        gather cluster level info.\n",
    "        '''\n",
    "        head_sid = headmen['sid'].values #extract all values\n",
    "        new_sids = []\n",
    "        new_sids.extend(head_sid)\n",
    "        clust_head_of_head = mens.ix[headmen_id, 'clust_head'] # find head of head mention.\n",
    "        for mer in merges:\n",
    "            mer_men = mens[mens['shift'] == mer]\n",
    "            mer_sid = mer_men['sid'].values\n",
    "            mer_id = mer_men.index.tolist()[0] #check functioning!\n",
    "            new_sids.extend(mer_sid)\n",
    "            if not clust_head_of_head == '_': # adds head_clust of headmen to mention if it exists.\n",
    "                mens.ix[mer_id, 'clust_head'] = clust_head_of_head\n",
    "            else:\n",
    "                mens.ix[mer_id, 'clust_head'] = headmen['shift'].values[0] #shift head\n",
    "        new_sids = ', '.join(list(set([str(x) for x in new_sids])))\n",
    "        mens.ix[headmen_id, 'sid_corefs'] = new_sids\n",
    "        return mens\n",
    "            \n",
    "            \n",
    "            \n",
    "    def merge(self, mens, men_dict, manual, morph_merge, gold): # main merge function.\n",
    "        '''\n",
    "        merges data for corefering mentions(i.e. sid, shift of all), appending necessary \n",
    "        info to head mention (often most informative mention.), removes all child \n",
    "        mentions from mention list, replaces child mention pairings in candidate list with head word. \n",
    "        Because features are aggregated across all mentions in cluster, will not make impact on performance.\n",
    "        '''      \n",
    "        if manual == True:\n",
    "            for ment, merges in men_dict.items():\n",
    "                skip = False\n",
    "                headmen = mens[mens['shift'] == ment]\n",
    "                if gold == True: #to select for merging in gold model, only those that exist.\n",
    "                    indexes = []\n",
    "                    if not headmen.empty:\n",
    "                        indexes.append(ment)\n",
    "                    for mer in merges:\n",
    "                        mermen = mens[mens['shift'] == mer]\n",
    "                        if not mermen.empty:\n",
    "                            indexes.append(mer)\n",
    "                    if len(indexes) > 0:\n",
    "                        indexes.sort() # to get the most early occuring mention first in order.\n",
    "                        head_sh = indexes[0]\n",
    "                        headmen = mens[mens['shift'] == head_sh]\n",
    "                        headmen_id = headmen.index.tolist()[0]\n",
    "                        del indexes[0]\n",
    "                        merges = indexes \n",
    "                    else:\n",
    "                        skip = True\n",
    "                else:\n",
    "                    try: #because of trying to train mens and deps at same time\n",
    "                        headmen_id = headmen.index.tolist()[0]\n",
    "                    except IndexError:\n",
    "                        print('first ment error!', ment)               \n",
    "                if skip == False:\n",
    "                    mens.ix[headmen_id, 'corefs'] = ', '.join([str(x) for x in merges]) # add shifts of all corefering mentions\n",
    "                    if len(merges) > 0:\n",
    "                        if morph_merge == True:\n",
    "                            new_mor = self.morph_merge(headmen, merges, mens)\n",
    "                            mens.ix[headmen_id, 'morph'] = new_mor\n",
    "                        mens = self.sid_merge(headmen, headmen_id, merges, mens) \n",
    "                    mens = mens.fillna('_')\n",
    "            return mens  \n",
    "    \n",
    "    \n",
    "    def form_frame(self, deps, mens, type_all, l_sids, r_sids, sid, typ, goldm):\n",
    "        if type_all == 'pron':\n",
    "            if typ in ('pron', 'poss'):\n",
    "                rng = 3\n",
    "                frame = self.create_frames(l_sids, r_sids, sid, rng, deps, goldm, mens)#sentence frames for candidate searching.\n",
    "            elif typ in ('refl', 'rel'):\n",
    "                if goldm == False:\n",
    "                    frame = deps[deps['sid'] == sid]\n",
    "                else:\n",
    "                    frame = mens[mens['sid'] == sid]\n",
    "            else:\n",
    "                frame = []\n",
    "        elif type_all == 'ne-ne':\n",
    "            if typ == 'NE':\n",
    "                rng = 4\n",
    "                frame = self.create_frames(l_sids, r_sids, sid, rng, deps, goldm, mens)\n",
    "            else:\n",
    "                frame = []\n",
    "        elif type_all == 'ne-noun':\n",
    "            if typ == 'NE':\n",
    "                rng = 4\n",
    "                frame = self.create_frames(l_sids, r_sids, sid, rng, deps, goldm, mens)\n",
    "            else:\n",
    "                frame = []\n",
    "        elif type_all == 'noun-noun':\n",
    "            if typ == 'noun':\n",
    "                rng = 4\n",
    "                frame = self.create_frames(l_sids, r_sids, sid, rng, deps, goldm, mens)\n",
    "            else:\n",
    "                frame = [] #catch gold mens to deps descrepancies for training set. Just skip.\n",
    "        return frame\n",
    "    \n",
    "            \n",
    "    def set_up_frames(self, ment, typ, type_all, deps, mens, train, goldm):  \n",
    "        '''\n",
    "        sort frame ranges and frames for different mentions.\n",
    "        '''\n",
    "        sid = int(ment['sid'])\n",
    "        sid_max = int(deps['sid'][deps['sid'].idxmax()])\n",
    "        ment_sh = ment['shift']\n",
    "        l_sids = 0\n",
    "        r_sids = 0\n",
    "        if sid < 4: #finds left and right boundaries if sentence at beginning or end of doc.\n",
    "            l_sids = [x for x in range(1, sid+1)]\n",
    "        elif (sid_max - sid) < 4:\n",
    "            r_sids = [x for x in range(sid, sid_max+1)]\n",
    "        frames = self.form_frame(deps, mens, type_all, l_sids, r_sids, sid, typ, goldm)\n",
    "        return frames\n",
    "    \n",
    "\n",
    "    def create_frames(self, l_sids, r_sids, sid, rng, deps, goldm, mens):\n",
    "        '''\n",
    "        creates frames for mention search.\n",
    "        '''\n",
    "        if goldm == False:\n",
    "            if not l_sids == 0 and not r_sids == 0:\n",
    "                l_len = len(l_sids)\n",
    "                r_len = len(r_sids)\n",
    "                if l_len > 0 and r_len > 0:\n",
    "                    frame = deps.query('{0} <= sid <= {1}'.format(l_sids, r_sids))\n",
    "                elif l_len > 0 and not r_len > 0:\n",
    "                    frame = deps.query('{0} <= sid <= {1}'.format(l_sids, sid+rng))\n",
    "                elif r_len > 0 and not l_len > 0:\n",
    "                    frame = deps.query('{0} <= sid <= {1}'.format(sid-rng, r_sids))\n",
    "            else:\n",
    "                frame = deps.query('{0} <= sid <= {1}'.format(sid-rng, sid+rng))\n",
    "        else:\n",
    "            if not l_sids == 0 and not r_sids == 0:\n",
    "                l_len = len(l_sids)\n",
    "                r_len = len(r_sids)\n",
    "                if l_len > 0 and r_len > 0:\n",
    "                    frame = mens.query('{0} <= sid <= {1}'.format(l_sids, r_sids))\n",
    "                elif l_len > 0 and not r_len > 0:\n",
    "                    frame = mens.query('{0} <= sid <= {1}'.format(l_sids, sid+rng))\n",
    "                elif r_len > 0 and not l_len > 0:\n",
    "                    frame = mens.query('{0} <= sid <= {1}'.format(sid-rng, r_sids))\n",
    "            else:\n",
    "                frame = mens.query('{0} <= sid <= {1}'.format(sid-rng, sid+rng))\n",
    "        return frame\n",
    "\n",
    "    \n",
    "    def create_test_sets(self, ment, deps, frame, docid, df, ment_ser, goldm):\n",
    "        '''\n",
    "        appends rows to test sets for each ment\n",
    "        '''\n",
    "        ments = []\n",
    "        ment_sh = ment['shift']\n",
    "        ment_shs = ment['tk_shifts'].split(', ')\n",
    "        if not len(frame) == 0: #aviod skipped mentions.\n",
    "            for i, m in frame.iterrows():\n",
    "                m_sh = m['shift']\n",
    "                if m_sh in ment_shs or m_sh == ment_sh: # so not to capture mentions in mentions as possibly coreferent if they overlap at all.\n",
    "                    pass\n",
    "                elif not m['full_men'] == '_':\n",
    "                    ments.append(m_sh)\n",
    "            ments = list(set(ments))\n",
    "            tempval = {'docid':[docid], 'start_ref':[ment_sh], 'refs':[ments], 'series':[ment_ser]}\n",
    "            tempdf = pd.DataFrame(tempval)\n",
    "            df = df.append(tempdf)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def create_candidates(self, mens, deps, train, gold, no_gold, docid, \\\n",
    "                          train_ids, test_ids, type_all):\n",
    "        '''\n",
    "        creates initial candidate lists for training, gold mentions, and no gold mentions.\n",
    "        '''\n",
    "        if docid in test_ids:\n",
    "            for i, ment in deps.iterrows():\n",
    "                if not ment['full_men'] == '_' and not ment['udpos'] == 'PUNCT': #avoid non mentions and parsing errors.\n",
    "                    ment_typ = ment['type']\n",
    "                    if 'series' not in ment:\n",
    "                        ment['series'] = '_'\n",
    "                    ment_ser = ment['series']\n",
    "                    frame = self.set_up_frames(ment, ment_typ, type_all, deps, mens, train=False, goldm=False)\n",
    "                    no_gold = self.create_test_sets(ment, deps, frame, docid, no_gold, ment_ser, goldm=False)\n",
    "        for i, ment in mens.iterrows():\n",
    "            if not ment['udpos'] == 'PUNCT' and not ment['full_men'] =='_':\n",
    "                if 'series' not in ment:\n",
    "                    ment['series'] = '_'\n",
    "                if docid in test_ids:\n",
    "                    ment_typ = ment['type']\n",
    "                    ment_ser = ment['series']\n",
    "                    frame = self.set_up_frames(ment, ment_typ, type_all, deps, mens, train=False, goldm=True)\n",
    "                    gold = self.create_test_sets(ment, deps, frame, docid, gold, ment_ser, goldm=True)\n",
    "                else:\n",
    "                    sid = int(ment['sid'])\n",
    "                    ment_sh = ment['shift']\n",
    "                    ment_typ = ment['type']\n",
    "                    ment_ser = ment['series']\n",
    "                    frame = self.set_up_frames(ment, ment_typ, type_all, deps, mens, train=True, goldm=False) # create frame.\n",
    "                    if len(frame) == 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        cor_id = ment['chain_id']\n",
    "                        cor_men = mens['shift'][mens['chain_id'] == cor_id].tolist()\n",
    "                        cor_ments = []\n",
    "                        for cor in cor_men:\n",
    "                            ment_temp = frame[frame['shift'] == cor]\n",
    "                            cor_ments.append(ment_temp)\n",
    "                        n_cor_ments = []\n",
    "                        for df in cor_ments:\n",
    "                            if df.empty:\n",
    "                                pass\n",
    "                            elif df['shift'].values[0] == ment_sh:\n",
    "                                pass\n",
    "                            else:\n",
    "                                n_cor_ments.append(df)\n",
    "                        if len(n_cor_ments) == 0: #for refs that can't be found within the given frame.\n",
    "                            pass\n",
    "                        else:\n",
    "                            cor = random.choice(n_cor_ments) # in order to randomly choose mentions.\n",
    "                            cor_sh = cor['shift'].values[0]\n",
    "                            if cor_sh > ment_sh: #select incorrect only if it's between correct\n",
    "                                incors = frame[(ment_sh < frame['shift']) & (frame['shift'] < cor_sh)]\n",
    "                            elif ment_sh > cor_sh:\n",
    "                                incors = frame[(cor_sh < frame['shift']) & (frame['shift'] < ment_sh)]\n",
    "                            incor_ments = []\n",
    "                            for i, incorr in incors.iterrows():\n",
    "                                if incorr['shift'] in cor_men or incorr['shift'] == ment_sh:\n",
    "                                    pass\n",
    "                                elif not incorr['full_men'] == '_': #weed out non mentions\n",
    "                                    incor_ments.append(incorr)\n",
    "                            if len(incor_ments) == 0: # if no possible mentions in between.\n",
    "                                if cor_sh > ment_sh: #select any possible mention in frame.\n",
    "                                    incors = frame[(cor_sh < frame['shift']) | (frame['shift'] < ment_sh)]\n",
    "                                elif ment_sh > cor_sh:\n",
    "                                    incors = frame[(ment_sh < frame['shift']) | (frame['shift'] < cor_sh)]\n",
    "                                for i, incorr in incors.iterrows():\n",
    "                                    if incorr['shift'] in cor_men or incorr['shift'] == ment_sh:\n",
    "                                        pass\n",
    "                                    elif not incorr['full_men'] == '_': #weed out non mentions\n",
    "                                        incor_ments.append(incorr)\n",
    "                            if len(incor_ments) == 0: # If no other posible mentions in frame besides correct men\n",
    "                                incors = deps[deps['sid'] == sid + 1] # add following sent so there is a value\n",
    "                                for i, incorr in incors.iterrows():\n",
    "                                    if incorr['shift'] in cor_men or incorr['shift'] == ment_sh:\n",
    "                                        pass\n",
    "                                    elif not incorr['full_men'] == '_': #weed out non mentions\n",
    "                                        incor_ments.append(incorr)\n",
    "                                if len(incor_ments) == 0: # If no other posible mentions in frame besides correct men\n",
    "                                    incors = deps[deps['sid'] == sid - 1] # add following sent so there is a value\n",
    "                                    for i, incorr in incors.iterrows():\n",
    "                                        if incorr['shift'] in cor_men or incorr['shift'] == ment_sh:\n",
    "                                            pass\n",
    "                                        elif not incorr['full_men'] == '_': #weed out non mentions\n",
    "                                            incor_ments.append(incorr)\n",
    "                            incor = random.choice(incor_ments)\n",
    "                            incor_sh = incor['shift']\n",
    "                            tempval = {'docid':[docid], 'start_ref':[ment_sh], 'cor':[cor_sh], 'incor':[incor_sh], 'series':[ment_ser]}\n",
    "                            tempdf = pd.DataFrame(tempval)\n",
    "                            train = train.append(tempdf)\n",
    "        return train, gold, no_gold\n",
    "      \n",
    "    \n",
    "    \n",
    "    def compare(self, title, val, temp_ref, start_ment, ref_ment):\n",
    "        '''\n",
    "        module for comparing values of two mentions. Appends 1 for True, 0 for False to given title.\n",
    "        '''\n",
    "        skip = False\n",
    "        stop = False\n",
    "        if not start_ment.empty or not ref_ment.empty:\n",
    "            if val == 'morph': #because need to split morph values.\n",
    "                start_morph = start_ment[val].values[0].split('|')\n",
    "                ref_morph = ref_ment[val].values[0].split('|')\n",
    "                if skip == False:\n",
    "                    stopg = False # set stops to false default\n",
    "                    stopa = False\n",
    "                    stopn = False\n",
    "                    stopp = False\n",
    "                    stopgr = False\n",
    "                    stopar = False\n",
    "                    stopnr = False\n",
    "                    stoppr = False\n",
    "                    for morph in start_morph: # determine existance of morph\n",
    "                        if title == 'genderm':\n",
    "                            if morph.startswith('Gender=') and stopg == False:\n",
    "                                stopg = True\n",
    "                        elif title == 'animacym':\n",
    "                            if morph.startswith('Animacy=') and stopa == False:\n",
    "                                stopa = True\n",
    "                        elif title == 'numberm':\n",
    "                            if morph.startswith('Number=') and stopn == False:\n",
    "                                stopn = True\n",
    "                        elif title == 'person_match':\n",
    "                            if morph.startswith('Person=') and stopp == False:\n",
    "                                stopp = True\n",
    "\n",
    "                    for morph in ref_morph:\n",
    "                        if title == 'genderm':\n",
    "                            if morph.startswith('Gender=') and stopgr == False:\n",
    "                                stopgr = True\n",
    "                        elif title == 'animacym':\n",
    "                            if morph.startswith('Animacy=') and stopar == False:\n",
    "                                stopar = True\n",
    "                        elif title == 'numberm':\n",
    "                            if morph.startswith('Number=') and stopnr == False:\n",
    "                                stopnr = True\n",
    "                        elif title == 'person_match':\n",
    "                            if morph.startswith('Person=') and stoppr == False:\n",
    "                                stoppr= True\n",
    "\n",
    "\n",
    "                    if val == 'clustagree':   \n",
    "                        if stopg == False:\n",
    "                            start_val_gen = None\n",
    "                        if stopa == False:\n",
    "                            start_val_ani = None\n",
    "                        if stopn == False:\n",
    "                            start_val_num = None\n",
    "                        if stopgr == False:\n",
    "                            ref_val_gen = None\n",
    "                        if stopar == False:\n",
    "                            ref_val_ani = None\n",
    "                        if stopnr == False:\n",
    "                            ref_val_num = None\n",
    "\n",
    "                        for morph in start_morph:\n",
    "                            if morph.startswith('Gender='):\n",
    "                                start_val_gen = morph\n",
    "                            if morph.startswith('Animacy='):\n",
    "                                start_val_ani = morph\n",
    "                            if morph.startswith('Number='):\n",
    "                                start_val_num = morph\n",
    "\n",
    "\n",
    "                        for morph in ref_morph:\n",
    "                            if morph.startswith('Gender='):\n",
    "                                ref_val_gen = morph\n",
    "                            if morph.startswith('Animacy='):\n",
    "                                ref_val_ani = morph\n",
    "                            if morph.startswith('Number='):\n",
    "                                ref_val_num = morph\n",
    "                        if start_val_gen == ref_val_gen and start_val_ani == ref_val_ani and start_val_num == ref_val_num \\\n",
    "                        and not (start_val_gen == None or start_val_ani == None or start_val_num == None or ref_val_gen == None \\\n",
    "                        or ref_val_ani == None or ref_val_num == None):\n",
    "                            temp_ref[title] = [1]\n",
    "                        else:\n",
    "                            temp_ref[title] = [0]\n",
    "                        return temp_ref\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        if (stopg or stopa or stopa or stopp) == False:\n",
    "                            start_val = None\n",
    "\n",
    "                        if (stopgr or stopar or stopar or stoppr) == False:\n",
    "                            ref_val = None\n",
    "\n",
    "\n",
    "                        for morph in start_morph:\n",
    "                            if title == 'genderm':\n",
    "                                if morph.startswith('Gender='):\n",
    "                                    start_val = morph\n",
    "                            elif title == 'animacym':\n",
    "                                if morph.startswith('Animacy='):\n",
    "                                    start_val = morph\n",
    "                            elif title == 'numberm':\n",
    "                                if morph.startswith('Number='):\n",
    "                                    start_val = morph\n",
    "                            elif title == 'person_match':\n",
    "                                if morph.startswith('Person='):\n",
    "                                    start_val = morph\n",
    "\n",
    "\n",
    "                        for morph in ref_morph:\n",
    "                            if title == 'genderm':\n",
    "                                if morph.startswith('Gender='):\n",
    "                                    ref_val = morph\n",
    "                            elif title == 'animacym':\n",
    "                                if morph.startswith('Animacy='):\n",
    "                                    ref_val = morph\n",
    "                            elif title == 'numberm':\n",
    "                                if morph.startswith('Number='):\n",
    "                                    ref_val = morph\n",
    "                            elif title == 'person_match':\n",
    "                                if morph.startswith('Person='):\n",
    "                                    ref_val = morph\n",
    "                                    \n",
    "            else: # for all other compares, without special format\n",
    "                start_val = start_ment[val].values[0]\n",
    "                ref_val = ref_ment[val].values[0]\n",
    "        else:\n",
    "            stop = True\n",
    "\n",
    "#         if ('start_val' in locals() or 'start_val' in globals()) \\\n",
    "#         and ('ref_val' in locals() or 'ref_val' in globals()):\n",
    "        \n",
    "        if not title == 'clustagree':\n",
    "            if stop == False:\n",
    "                if ref_val == start_val and not (ref_val or start_val) == None:\n",
    "                    temp_ref[title] = [1]\n",
    "                else:\n",
    "                    temp_ref[title] = [0]\n",
    "            else:\n",
    "                temp_ref[title] = [0]\n",
    "\n",
    "#         else:\n",
    "#             temp_ref[title] = [0]\n",
    "        \n",
    "        return temp_ref\n",
    "            \n",
    "            \n",
    "    def partialheadm(self, title, val, temp_ref, start_ment, ref_ment, deps):\n",
    "        '''\n",
    "        relaxed head mention match. If any nouns or proper nouns in mention match returns 1 for true.\n",
    "        '''\n",
    "        if not start_ment.empty or ref_ment.empty:\n",
    "            skip = False\n",
    "            start_shs = start_ment[val].values[0].split(',')\n",
    "            ref_shs = ref_ment[val].values[0].split(',')\n",
    "            if len(ref_shs) > 0:\n",
    "                for stsh in start_shs:\n",
    "                    if not stsh == '_':\n",
    "                        st = deps[deps['shift'] == float(stsh)]\n",
    "                        st_pos = st['udpos'].values[0]\n",
    "                        if st_pos in ('NOUN', 'PROPN'): #so that not just pairing anything\n",
    "                            st_lem = st['lemma'].values[0]\n",
    "                            for refsh in ref_shs:\n",
    "                                if not refsh == '_':\n",
    "                                    rf = deps[deps['shift'] == float(refsh)]\n",
    "                                else:\n",
    "                                    skip = True\n",
    "                            if skip == False:\n",
    "                                rf_lem = rf['lemma'].values[0]\n",
    "                                if st_lem == rf_lem:  # compare the two\n",
    "                                    temp_ref[title] = [1]\n",
    "                    else:\n",
    "                        temp_ref[title] = [0]\n",
    "                if temp_ref[title].empty:\n",
    "                    temp_ref[title] = [0]\n",
    "            else:\n",
    "                temp_ref[title] = [0]\n",
    "        else:\n",
    "            temp_ref[title] = [0]\n",
    "        return temp_ref\n",
    "                    \n",
    "        \n",
    "    def distance(self, title, val, temp_ref, start_ment, ref_ment):\n",
    "        '''\n",
    "        finds distance bewteen given start and finish, depending on variable.\n",
    "        '''\n",
    "        start_sid = start_ment[val].values[0]\n",
    "        ref_sid = ref_ment[val].values[0]\n",
    "        dif = int(start_sid) - int(ref_sid) #can be negative to account for direction.\n",
    "        temp_ref[title] = [dif]\n",
    "        return temp_ref\n",
    "           \n",
    "        \n",
    "    def sing_to_plur(self, morph):\n",
    "        '''\n",
    "        Change number of series to plural\n",
    "        '''\n",
    "        morph = ['Number=Plur' if x=='Number=' else x for x in morph]\n",
    "        morph = '|'.join(morph)\n",
    "        return morph\n",
    "      \n",
    "        \n",
    "    def find_val(self, title, val, temp_ref, start_ment, deps, find):\n",
    "        '''\n",
    "        returns 1 for true if head begins with a determiner.\n",
    "        '''\n",
    "        if val == 'tk_shifts':\n",
    "            st_first = start_ment[val].values[0]\n",
    "            if not type(st_first) == float:\n",
    "                st_first = st_first.split(',')[0]\n",
    "            if not st_first == '_':\n",
    "                st_f_pos = deps[deps['shift'] == float(st_first)]['udpos'].values[0]\n",
    "                if st_f_pos == find:\n",
    "                    temp_ref[title] = [1]\n",
    "                else:\n",
    "                    temp_ref[title] = [0]\n",
    "            else:\n",
    "                temp_ref[title] = [0]\n",
    "        elif val in ('deprel', 'type', 'shift', 'containnum'):\n",
    "            st_first = start_ment[val].values[0]\n",
    "            if st_first == find:\n",
    "                temp_ref[title] = [1]\n",
    "            else:\n",
    "                temp_ref[title] = [0]\n",
    "        return temp_ref\n",
    "        \n",
    "        \n",
    "    def get_val(self, title, val, temp_ref, start_ment):\n",
    "        temp_ref[title] = [start_ment[val].values[0]]\n",
    "        return temp_ref\n",
    "    \n",
    "    \n",
    "    def comb_attr(self, title, val, temp_ref, start_ment, ref_ment):\n",
    "        if not start_ment.empty:\n",
    "            start_val = start_ment[val].values[0]\n",
    "            ref_val = ref_ment[val].values[0]\n",
    "            new_val = '-'.join((start_val, ref_val))\n",
    "            temp_ref[title] = [new_val]\n",
    "        else:\n",
    "            temp_ref[title] = '_'\n",
    "        return temp_ref\n",
    "        \n",
    "    \n",
    "    def clust_info(self, title, val, temp_ref, start_ment, ref_ment, deps, act):\n",
    "        '''\n",
    "        for gathering and comparing cluster level info.\n",
    "        '''\n",
    "        ref_head = deps[deps['shift'] == float(ref_ment['head'].values[0])]\n",
    "        start_head = deps[deps['shift'] == float(start_ment['head'].values[0])]\n",
    "        if act == 'compare':\n",
    "            title = title\n",
    "            val = 'morph'\n",
    "            temp_ref.merge(self.compare(title, val, temp_ref, start_ment, ref_ment))\n",
    "        return temp_ref\n",
    "     \n",
    "        \n",
    "    def w2v(self, title, temp_ref, w2vmod, start_ment, ref_ment):\n",
    "        '''\n",
    "        retrives word2vec similarity scores for words\n",
    "        '''\n",
    "        start_lem = start_ment['lemma'].values[0]\n",
    "        ref_lem = ref_ment['lemma'].values[0]\n",
    "        start_pos = start_ment['udpos'].values[0]\n",
    "        ref_pos = ref_ment['udpos'].values[0]\n",
    "        start_fin = '_'.join((start_lem, start_pos))\n",
    "        ref_fin = '_'.join((ref_lem, ref_pos))\n",
    "        try:\n",
    "            score = w2vmod.similarity(start_fin, ref_fin)\n",
    "            temp_ref[title] = score\n",
    "        except KeyError:\n",
    "            temp_ref[title] = 0\n",
    "        return temp_ref\n",
    "    \n",
    "    \n",
    "    def wordnet(self, start_ment):\n",
    "        '''\n",
    "        set up word list for checking.\n",
    "        '''\n",
    "        translator = Translator()\n",
    "        trans = translator.translate(start_ment['lemma'].values[0], dest = 'en')\n",
    "        word = trans.text\n",
    "        syns = wn.synsets(word)\n",
    "        new_list = []\n",
    "        for syn in syns:\n",
    "            for l in syn.lemmas():\n",
    "                if l.name() not in new_list:\n",
    "                    new_list.append(l.name().replace('_', ' '))\n",
    "        trans = translator.translate(new_list, dest = 'ru')\n",
    "        ru_list = []\n",
    "        for tran in trans:\n",
    "            ru_list.append(tran.text)\n",
    "        return ru_list\n",
    "    \n",
    "    \n",
    "    def in_list(self, title, val, temp_ref, start_list, ref_ment):\n",
    "        '''\n",
    "        check if something is in list. 1 for true.\n",
    "        '''\n",
    "        ref_val = ref_ment[val].values[0]\n",
    "        if ref_val in start_list:\n",
    "            temp_ref[title] = 1\n",
    "        else:\n",
    "            temp_ref[title] = 0\n",
    "        return temp_ref\n",
    "    \n",
    "        \n",
    "    def make_vars(self, deps, starts, refs, var_list, typ, w2vmod, train):\n",
    "        '''\n",
    "        makes vars sets for each mention.\n",
    "        '''\n",
    "        ret = False\n",
    "        all_refs = []#list for temp storing of mention comparisons.\n",
    "        for start in starts:\n",
    "            try:\n",
    "                if start['udpos'].values[0]:\n",
    "                    wnet_list = self.wordnet(start) #set up wnet list once.\n",
    "                    for ref in refs:\n",
    "                        ref_ment = deps[deps['shift'] == ref]\n",
    "                        temp_ref = pd.DataFrame(columns=var_list)\n",
    "                        if 'genderm' in var_list:\n",
    "                            title = 'genderm'\n",
    "                            val = 'morph'\n",
    "                            temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'numberm' in var_list:\n",
    "                            title = 'numberm'\n",
    "                            val = 'morph'\n",
    "                            temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'headm' in var_list:\n",
    "                            title = 'headm'\n",
    "                            val = 'lemma'\n",
    "                            temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'partialheadm' in var_list:\n",
    "                            title = 'partialheadm'\n",
    "                            val = 'tk_shifts'\n",
    "                            temp_ref.merge(self.partialheadm(title, val, temp_ref, start, ref_ment, deps))\n",
    "                        if 'sentdist' in var_list:\n",
    "                            title = 'sentdist'\n",
    "                            val = 'sid'\n",
    "                            temp_ref.merge(self.distance(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'shiftdist' in var_list:\n",
    "                            title = 'shiftdist'\n",
    "                            val = 'shift'\n",
    "                            temp_ref.merge(self.distance(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'detmen' in var_list:\n",
    "                            title = 'detmen'\n",
    "                            val = 'tk_shifts'\n",
    "                            find = 'DET'\n",
    "                            temp_ref.merge(self.find_val(title, val, temp_ref, start, deps, find))\n",
    "                        if 'detref' in var_list:\n",
    "                            title = 'detref'\n",
    "                            val = 'tk_shifts'\n",
    "                            find = 'DET'\n",
    "                            temp_ref.merge(self.find_val(title, val, temp_ref, ref_ment, deps, find))\n",
    "                        if 'nsubjant' in var_list:\n",
    "                            title = 'nsubjant'\n",
    "                            val = 'deprel'\n",
    "                            find = 'nsubj'\n",
    "                            temp_ref.merge(self.find_val(title, val, temp_ref, ref_ment, deps, find))\n",
    "                        if 'nsubjmen' in var_list:\n",
    "                            title = 'nsubjmen'\n",
    "                            val = 'deprel'\n",
    "                            find = 'nsubj'\n",
    "                            temp_ref.merge(self.find_val(title, val, temp_ref, start, deps, find))\n",
    "                        if 'nar_match' in var_list:\n",
    "                            if not start['nar'].values[0] == '_':\n",
    "                                title = 'nar_match'\n",
    "                                val = 'nar'\n",
    "                                temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'antecedenttype' in var_list:\n",
    "                            title = 'antecedenttype'\n",
    "                            val = 'type'\n",
    "                            temp_ref.merge(self.get_val(title, val, temp_ref, ref_ment))\n",
    "                        if 'namepartref' in var_list:\n",
    "                            title = 'namepartref'\n",
    "                            val = 'deprel'\n",
    "                            find = 'flat:name'\n",
    "                            temp_ref.merge(self.find_val(title, val, temp_ref, ref_ment, deps, find))\n",
    "                        if 'isrefspeaker' in var_list:\n",
    "                            title = 'isrefspeaker'\n",
    "                            val = 'shift'\n",
    "                            find = start['nar'].values[0]\n",
    "                            temp_ref.merge(self.find_val(title, val, temp_ref, ref_ment, deps, find))\n",
    "                        if 'deproleant' in var_list:\n",
    "                            title = 'deproleant'\n",
    "                            val = 'deprel'\n",
    "                            temp_ref.merge(self.get_val(title, val, temp_ref, ref_ment))\n",
    "                        if 'deprolemen' in var_list:\n",
    "                            title = 'deprolemen'\n",
    "                            val = 'deprel'\n",
    "                            temp_ref.merge(self.get_val(title, val, temp_ref, start))\n",
    "                        if 'deprolecomb' in var_list:\n",
    "                            title = 'deprolecomb'\n",
    "                            val = 'deprel'\n",
    "                            temp_ref.merge(self.comb_attr(title, val, temp_ref, start, ref_ment))\n",
    "                        if 'samesent' in var_list:\n",
    "                            title = 'samesent'\n",
    "                            val = 'sid'\n",
    "                            temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "\n",
    "                            \n",
    "                        ref_pos = ref_ment['udpos'].values[0]\n",
    "\n",
    "                        if typ == 'noun': #noun specific vars\n",
    "                            if ref_pos in ('NOUN', 'PROPN'):\n",
    "                                if 'animacym' in var_list and ref_pos in ('NOUN', 'PROPN'):\n",
    "                                    title = 'animacym'\n",
    "                                    val = 'morph'\n",
    "                                    temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                                if 'clustagree' in var_list: #cluster level info\n",
    "                                    title = 'clustagree'\n",
    "                                    val = 'morph'\n",
    "                                    act = 'compare'\n",
    "                                    temp_ref.merge(self.clust_info(title, val, temp_ref, start, ref_ment, deps, act))\n",
    "                                if 'containnum' in var_list: #cluster level info\n",
    "                                    title = 'containnum'\n",
    "                                    val = 'udpos'\n",
    "                                    find = 'NUM'\n",
    "                                    temp_ref.merge(self.find_val(title, val, temp_ref, ref_ment, deps, find))\n",
    "                                if 'w2v_sim' in var_list:\n",
    "                                    title = 'w2v_sim'\n",
    "                                    temp_ref.merge(self.w2v(title, temp_ref, w2vmod, start, ref_ment))\n",
    "                                if 'wnet_syn' in var_list:\n",
    "                                    title = 'wnet_syn'\n",
    "                                    var = 'lemma'\n",
    "                                    start_list = wnet_list\n",
    "                                    temp_ref.merge(self.in_list(title, var, temp_ref, start_list, ref_ment))\n",
    "\n",
    "                        elif typ == 'ne': #Ne specific vars\n",
    "                            if ref_pos in ('NOUN', 'PROPN'):\n",
    "                                if 'animacym' in var_list:\n",
    "                                    title = 'animacym'\n",
    "                                    val = 'morph'\n",
    "                                    temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                                if 'clustagree' in var_list: #cluster level info\n",
    "                                    title = 'clustagree'\n",
    "                                    val = 'morph'\n",
    "                                    act = 'compare'\n",
    "                                    temp_ref.merge(self.clust_info(title, val, temp_ref, start, ref_ment, deps, act))\n",
    "                            if 'NEtype_match' in var_list:\n",
    "                                title = 'NEtype_match'\n",
    "                                val = 'ne_type'\n",
    "                                temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment))\n",
    "                            if 'namepart' in var_list: #part of a name, not head. Ideally learns to not pair these.\n",
    "                                title = 'namepart'\n",
    "                                val = 'deprel'\n",
    "                                find = 'flat:name'\n",
    "                                temp_ref.merge(self.find_val(title, val, temp_ref, start, deps, find))\n",
    "                            if 'w2v_sim' in var_list:\n",
    "                                title = 'w2v_sim'\n",
    "                                temp_ref.merge(self.w2v(title, temp_ref, w2vmod, start, ref_ment))\n",
    "                            if 'wnet_syn' in var_list:\n",
    "                                title = 'wnet_syn'\n",
    "                                var = 'lemma'\n",
    "                                start_list = wnet_list\n",
    "                                temp_ref.merge(self.in_list(title, var, temp_ref, start_list, ref_ment))\n",
    "\n",
    "\n",
    "\n",
    "                        elif typ == 'pron': # pronoun specific vars\n",
    "                            if 'person_match' in var_list:\n",
    "                                title = 'person_match'\n",
    "                                val = 'morph'\n",
    "                                temp_ref.merge(self.compare(title, val, temp_ref, start, ref_ment)) \n",
    "                            if 'ptypemen' in var_list:\n",
    "                                title = 'ptypemen'\n",
    "                                val = 'deprel'\n",
    "                                temp_ref.merge(self.get_val(title, val, temp_ref, start))\n",
    "\n",
    "                        temp_ref = temp_ref.fillna(0)\n",
    "                        all_refs.append(temp_ref)\n",
    "            except IndexError:\n",
    "                ret = True\n",
    "        if ret == False and all_refs:\n",
    "            all_refdf = pd.concat(all_refs)\n",
    "            return all_refdf\n",
    "        else:\n",
    "            return 'skip'\n",
    "\n",
    "            \n",
    "    \n",
    "    def set_up_vars(self, docid, row, deps, df, answers, var_list, typ, ids, w2vmod, train):#add docid\n",
    "        '''\n",
    "        set up variables adn dfs for creating vars.\n",
    "        '''\n",
    "        if train == True:\n",
    "            start_refs = [deps[deps['shift'] == row.start_ref]] # can't be more than one, but program accepts lists here.\n",
    "            cor_ref = row.cor\n",
    "            incor_ref = row.incor\n",
    "            refs = [cor_ref, incor_ref]\n",
    "            tempdf = self.make_vars(deps, start_refs, refs, var_list, typ, w2vmod, train) # appends head ref pair variables\n",
    "            if not type(tempdf) == str:\n",
    "                df = pd.concat([df, tempdf])\n",
    "                for start_ref in start_refs:\n",
    "                    iddf_cor = pd.DataFrame({'docid': [docid], 'start': start_ref['shift'], 'ref':cor_ref})\n",
    "                    iddf_incor = pd.DataFrame({'docid': [docid], 'start': start_ref['shift'], 'ref':incor_ref})\n",
    "                    ids = ids.append(iddf_cor)\n",
    "                    ids = ids.append(iddf_incor)\n",
    "                    answers = answers.append(pd.DataFrame({'answer': [1]}))\n",
    "                    answers = answers.append(pd.DataFrame({'answer': [0]}))\n",
    "        elif train == False:\n",
    "            ser = row.series\n",
    "            if ser == True:#change morph for series to plural and split seperate mention for singular short ref.\n",
    "                start_ment = deps[deps['shift'] == row.start_ref]\n",
    "                start_ment_full = start_ment\n",
    "                start_ment_full['morph'] = self.sing_to_plur(start_ment['morph'].values[0].split('|'))\n",
    "                start_ment_part = start_ment\n",
    "                start_ment_part['full_men'] = start_ment_part['part_men']\n",
    "                start_ment_part['tk_shifts'] = start_ment_part['part_shifts']\n",
    "                start_refs = [start_ment_full, start_ment_part]\n",
    "            else:\n",
    "                start_refs = [deps[deps['shift'] == row.start_ref]]\n",
    "            refs = row.refs\n",
    "            tempdf = self.make_vars(deps, start_refs, refs, var_list, typ, w2vmod, train)\n",
    "            if not type(tempdf) == str:\n",
    "                df = pd.concat([df, tempdf])\n",
    "                c = 1\n",
    "                sery = 'false'\n",
    "                for start_ref in start_refs:\n",
    "                    if len(start_refs) > 1: \n",
    "                        if c > 1:\n",
    "                            sery = 'sing'\n",
    "                        c += 1\n",
    "                        for ref in refs:\n",
    "                            iddf = pd.DataFrame({'docid': [docid], 'start': start_ref['shift'], 'ref':ref, \\\n",
    "                                                'series': [sery]})\n",
    "                            ids = ids.append(iddf)   \n",
    "                    for ref in refs:\n",
    "                        iddf = pd.DataFrame({'docid': [docid], 'start': start_ref['shift'], 'ref':ref, \\\n",
    "                                            'series': [sery]})\n",
    "                        ids = ids.append(iddf)\n",
    "                               \n",
    "        return df, answers, ids\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "    def start_vars(self, deps, answers, train, gold_var, no_gold_var, \\\n",
    "                   train_ids, idstr, ids_gold, \\\n",
    "                   ids_nogold, test_ids, train_var, gold, no_gold, type_all, docid, var_list, w2vmod):\n",
    "        '''\n",
    "        create mention variable lists for training and testing.\n",
    "        '''\n",
    "        \n",
    "        if docid in train_ids: #make training data.\n",
    "            print('train')\n",
    "            traindoc = train[train['docid'] == docid]\n",
    "            for i, trow in traindoc.iterrows():\n",
    "                train_var, answers, idstr = self.set_up_vars(docid, trow, deps, train_var, answers, \\\n",
    "                                                                        var_list, type_all, idstr, w2vmod, train=True)\n",
    "            \n",
    "        elif docid in test_ids: # make test data\n",
    "            print('test')\n",
    "            no_answers = None\n",
    "            golddoc = gold[gold['docid'] == docid]\n",
    "            for i, rowg in golddoc.iterrows():\n",
    "                gold_var, no_answers, ids_gold = self.set_up_vars(docid, rowg, deps, gold_var, no_answers, \\\n",
    "                                                var_list, type_all, ids_gold, w2vmod, train=False)\n",
    "\n",
    "            \n",
    "\n",
    "            nogolddoc = no_gold[no_gold['docid'] == docid]\n",
    "            for i, rowng in nogolddoc.iterrows():\n",
    "                no_gold_var, no_answers, ids_nogold = self.set_up_vars(docid, rowng, deps, no_gold_var, no_answers, \\\n",
    "                                                    var_list, type_all, ids_nogold, w2vmod, train=False)\n",
    "\n",
    "        return answers, idstr, ids_gold, \\\n",
    "        ids_nogold, train_var, gold_var, no_gold_var, \n",
    "        \n",
    "        \n",
    "    def get_train_ids(self, train_per):\n",
    "        '''\n",
    "        randomizes training and test sets based on given percentage value, \n",
    "        returning the docids in two lists for training and testing.\n",
    "        '''\n",
    "        numlist = self.newdf.docid.values # all docid values to np array\n",
    "        train_per = math.floor(train_per * len(numlist))\n",
    "        train_ids = random.sample(numlist.tolist(), train_per) #harcoded quantity of texts.\n",
    "        test_ids = [x for x in numlist if x not in train_ids]\n",
    "        return train_ids, test_ids\n",
    "\n",
    "    \n",
    "    def create_vars(self, var_list, type_all, w2vmod, train_per, train_new = False, create_men=True):\n",
    "        '''\n",
    "        pass through manual sieves, collect mention pairs, and create final variable list for all \n",
    "        training and test data sets.\n",
    "        '''\n",
    "        if train_new == True:\n",
    "            self.train_ids, self.test_ids = self.get_train_ids(train_per) #set ids fro training\n",
    "        for i, nrow in self.newdf.iterrows():\n",
    "            docname = nrow.docname\n",
    "            print(docname)\n",
    "            docid = nrow.docid\n",
    "            \n",
    "            if type_all == 'noun':\n",
    "                mens = pd.read_csv('coref/men_1pass/{0}'.format(nrow.docname), delimiter='\\t') # temp method for testing.\n",
    "                deps = pd.read_csv('coref/1pass/{0}'.format(nrow.docname), delimiter='\\t')\n",
    "                \n",
    "                \n",
    "                \n",
    "                self.train_noun, self.gold_noun, \\\n",
    "                self.no_gold_noun = self.create_candidates(mens, deps, self.train_noun, self.gold_noun, self.no_gold_noun, \\\n",
    "                                                           docid, self.train_ids, self.test_ids, type_all)\n",
    "                \n",
    "                self.answers_noun, self.idstr_noun, self.ids_ne_gold, self.ids_ne_nogold, \\\n",
    "                self.train_var_noun, self.gold_var_noun, \\\n",
    "                self.no_gold_var_noun = self.start_vars(deps, self.answers_noun, \\\n",
    "                     self.train_noun, self.gold_var_noun, self.no_gold_var_noun, \\\n",
    "                     self.train_ids, self.idstr_noun, self.ids_noun_gold, \\\n",
    "                     self.ids_noun_nogold, self.test_ids, self.train_var_noun, \\\n",
    "                     self.gold_noun, self.no_gold_noun, type_all, docid, var_list, w2vmod)\n",
    "            \n",
    "            \n",
    "            elif type_all == 'ne':\n",
    "                mens = pd.read_csv('coref/men_sieves/{0}'.format(nrow.docname), delimiter='\\t') # temp method for testing.\n",
    "                deps = pd.read_csv('coref/sieves/{0}'.format(nrow.docname), delimiter='\\t')\n",
    "                \n",
    "                \n",
    "                \n",
    "                self.train_ne, self.gold_ne, \\\n",
    "                self.no_gold_ne = self.create_candidates(mens, deps, self.train_ne, self.gold_ne, self.no_gold_ne, \\\n",
    "                                                           docid, self.train_ids, self.test_ids, type_all)\n",
    "            \n",
    "            \n",
    "                self.answers_ne, self.idstr_ne, self.ids_ne_gold, self.ids_ne_nogold, \\\n",
    "                self.train_var_ne, self.gold_var_ne, \\\n",
    "                self.no_gold_var_ne = self.start_vars(deps, self.answers_ne, \\\n",
    "                     self.train_ne, self.gold_var_ne, self.no_gold_var_ne, \\\n",
    "                     self.train_ids, self.idstr_ne, self.ids_ne_gold, \\\n",
    "                     self.ids_ne_nogold, self.test_ids, self.train_var_ne, \\\n",
    "                     self.gold_ne, self.no_gold_ne, type_all, docid, var_list, w2vmod)\n",
    "                \n",
    "                \n",
    "            elif type_all == 'pron':\n",
    "                mens = pd.read_csv('coref/men_2pass/{0}'.format(nrow.docname), delimiter='\\t') # temp method for testing.\n",
    "                deps = pd.read_csv('coref/2pass/{0}'.format(nrow.docname), delimiter='\\t')\n",
    "                \n",
    "                \n",
    "                \n",
    "                self.train_pron, self.gold_pron, \\\n",
    "                self.no_gold_pron = self.create_candidates(mens, deps, self.train_pron, self.gold_pron, self.no_gold_pron, \\\n",
    "                                                           docid, self.train_ids, self.test_ids, type_all)\n",
    "\n",
    "                self.answers_pron, self.idstr_pron, self.ids_ne_gold, self.ids_ne_nogold, \\\n",
    "                self.train_var_pron, self.gold_var_pron, \\\n",
    "                self.no_gold_var_pron = self.start_vars(deps, self.answers_pron, \\\n",
    "                     self.train_pron, self.gold_var_pron, self.no_gold_var_pron, \\\n",
    "                     self.train_ids, self.idstr_pron, self.ids_pron_gold, \\\n",
    "                     self.ids_pron_nogold, self.test_ids, self.train_var_pron, \\\n",
    "                     self.gold_pron, self.no_gold_pron, type_all, docid, var_listt, w2vmod)\n",
    "            \n",
    "\n",
    "            if not os.path.exists('coref/sets'): #for testing only\n",
    "                os.mkdir('coref/sets')\n",
    "\n",
    "            if type_all == 'ne':\n",
    "\n",
    "                self.train_ne.to_csv('coref/sets/train_ne', sep='\\t')\n",
    "                self.gold_ne.to_csv('coref/sets/gold_ne', sep='\\t') \n",
    "                self.no_gold_ne.to_csv('coref/sets/no_gold_ne', sep='\\t')\n",
    "                self.train_var_ne.to_csv('coref/train_var_ne', sep='\\t')\n",
    "                self.gold_var_ne.to_csv('coref/gold_var_ne', sep='\\t')\n",
    "                self.no_gold_var_ne.to_csv('coref/nogold_var_ne', sep='\\t')\n",
    "                self.answers_ne.to_csv('coref/answers_ne', sep='\\t')\n",
    "                self.idstr_ne.to_csv('coref/idstr_ne', sep='\\t')\n",
    "                self.ids_ne_gold.to_csv('coref/ids_ne_gold', sep='\\t')\n",
    "                self.ids_ne_nogold.to_csv('coref/ids_ne_nogold', sep='\\t')\n",
    "\n",
    "            if type_all == 'noun':\n",
    "\n",
    "                self.train_noun.to_csv('coref/sets/train_noun', sep='\\t')\n",
    "                self.gold_noun.to_csv('coref/sets/gold_noun', sep='\\t')\n",
    "                self.no_gold_noun.to_csv('coref/sets/no_gold_noun', sep='\\t')\n",
    "                self.train_var_noun.to_csv('coref/train_var_noun', sep='\\t')\n",
    "                self.gold_var_noun.to_csv('coref/gold_var_noun', sep='\\t')\n",
    "                self.no_gold_var_noun.to_csv('coref/nogold_var_noun', sep='\\t')\n",
    "                self.answers_noun.to_csv('coref/answers_noun', sep='\\t')\n",
    "                self.idstr_noun.to_csv('coref/idstr_noun', sep='\\t')\n",
    "                self.ids_noun_gold.to_csv('coref/ids_noun_gold', sep='\\t')\n",
    "                self.ids_noun_nogold.to_csv('coref/ids_noun_nogold', sep='\\t')\n",
    "\n",
    "            if type_all == 'pron':\n",
    "\n",
    "                self.train_pron.to_csv('coref/sets/train_pron', sep='\\t')\n",
    "                self.gold_pron.to_csv('coref/sets/gold_pron', sep='\\t')\n",
    "                self.no_gold_pron.to_csv('coref/sets/no_gold_pron', sep='\\t')\n",
    "                self.train_var_pron.to_csv('coref/train_var_pron', sep='\\t')\n",
    "                self.gold_var_pron.to_csv('coref/gold_var_pron', sep='\\t')\n",
    "                self.no_gold_var_pron.to_csv('coref/nogold_var_pron', sep='\\t')\n",
    "                self.answers_pron.to_csv('coref/answers_pron', sep='\\t')\n",
    "                self.idstr_pron.to_csv('coref/idstr_pron', sep='\\t')\n",
    "                self.ids_pron_gold.to_csv('coref/ids_pron_gold', sep='\\t')    \n",
    "                self.ids_pron_nogold.to_csv('coref/ids_pron_nogold', sep='\\t')\n",
    "                        \n",
    "   \n",
    "\n",
    "    def make_dummies(self, inpt):\n",
    "            just_dummies = pd.get_dummies(inpt[['antecedenttype', 'deprolecomb', 'deproleant', 'deprolemen']])\n",
    "\n",
    "            plusdummies = pd.concat([inpt, just_dummies], axis=1)\n",
    "            plusdummies.drop(['antecedenttype', 'deprolecomb', 'deproleant', 'deprolemen'], \\\n",
    "                             inplace=True, axis=1)\n",
    "            plusdummies = plusdummies.applymap(np.int)\n",
    "            return plusdummies\n",
    "    \n",
    "    \n",
    "    def fix_dummies(self, df, columns ):\n",
    "        missing_cols = set( columns ) - set( df.columns ) # add columns from training\n",
    "        for c in missing_cols:\n",
    "            df[c] = 0\n",
    "            \n",
    "        extra_cols = set( df.columns ) - set( columns ) # subtract columns missning from training\n",
    "\n",
    "        df = df[ columns ]\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def train(self, ttype):\n",
    "        '''\n",
    "        Train\n",
    "        '''\n",
    "        clf_gini = RandomForestClassifier()\n",
    "        \n",
    "        if ttype == 'noun':\n",
    "            train_var = pd.read_csv('coref/noun_vars/train_var_noun', delimiter = '\\t')\n",
    "            answers = pd.read_csv('coref/noun_vars/answers_noun', delimiter = '\\t')\n",
    "\n",
    "            dummies = self.make_dummies(train_var)\n",
    "            \n",
    "            mod = clf_gini.fit(dummies, answers) \n",
    "            \n",
    "        elif ttype == 'ne':\n",
    "            train_var = pd.read_csv('coref/ne_vars/train_var_ne', delimiter = '\\t')\n",
    "            answers = pd.read_csv('coref/ne_vars/answers_ne', delimiter = '\\t')\n",
    "\n",
    "            dummies = self.make_dummies(train_var)\n",
    "            mod = clf_gini.fit(dummies, answers)\n",
    "\n",
    "            \n",
    "        elif ttype == 'pron':\n",
    "            train_var = pd.read_csv('coref/noun_vars/train_var_noun', delimiter = '\\t')\n",
    "            answers = pd.read_csv('coref/noun_vars/answers_noun', delimiter = '\\t')\n",
    "\n",
    "            dummies = self.make_dummies(train_var)\n",
    "            \n",
    "            mod = clf_gini.fit(dummies, answers)\n",
    "        \n",
    "        print(mod.score(dummies, answers))\n",
    "        cols = dummies.columns\n",
    "        return mod, cols\n",
    "        \n",
    "     \n",
    "    def fix_df(self, no_gold_var, gold_var):\n",
    "        no_gold_dummies = self.make_dummies(no_gold_var)\n",
    "        gold_dummies = self.make_dummies(gold_var)\n",
    "\n",
    "        no_gold_dummies = self.fix_dummies(no_gold_dummies, cols)\n",
    "        gold_dummies = self.fix_dummies(gold_dummies, cols)\n",
    "        return no_gold_dummies, gold_dummies\n",
    "\n",
    "    \n",
    "    def merge_dict(self, refs, ids):\n",
    "        merge_dict = defaultdict(list)\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for testid in ids['docid'].unique():\n",
    "            ids_frame = ids[ids['docid'] == testid]\n",
    "            ids_new = ids_frame.values.tolist()\n",
    "            ids_len = len(ids_new)\n",
    "            end += ids_len\n",
    "            ref_frame = refs[start:end]\n",
    "            start = end\n",
    "            doc_dict = defaultdict(list)\n",
    "            ban_list = []\n",
    "            c = 0\n",
    "            for ref in ref_frame:\n",
    "                c += 1\n",
    "                if ref[1] == 1.0:\n",
    "                    i = ids_new[c-1]\n",
    "                    i1 = i[4]\n",
    "                    i2 = i[2]\n",
    "                    if not i2 in ban_list:\n",
    "                        doc_dict[i1].append(i2)\n",
    "                        ban_list.append(i2)\n",
    "                        ban_list.append(i1)\n",
    "            merge_dict[testid] = doc_dict\n",
    "        return merge_dict\n",
    "            \n",
    "        \n",
    "    def merge_ml(self, merge_dict, gold, ttype): \n",
    "        for docid, v in merge_dict:\n",
    "            manual = True\n",
    "            morph_merge = True\n",
    "            men_dict = v\n",
    "            if gold == True:\n",
    "                mens = pd.read_csv('coref/men_sieves/{0}'.format(nrow.docname), delimiter='\\t')\n",
    "                self.merge(mens, men_dict, manual, morph_merge, gold)\n",
    "                mens = pd.read_csv('coref/men_1pass/{0}'.format(nrow.docname), delimiter='\\t') # temp method for testing.\n",
    "                deps = pd.read_csv('coref/1pass/{0}'.format(nrow.docname), delimiter='\\t')\n",
    "                \n",
    "            else:\n",
    "                deps = pd.read_csv('coref/sieves/{0}'.format(nrow.docname), delimiter='\\t')\n",
    "                self.merge(mens, men_dict, manual, morph_merge, gold)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def pipe(self, mod, ttype, cols):\n",
    "        '''\n",
    "        takes all models and pipes coresponding gold and no gold test sets through the model, \n",
    "        updating deps after each one.\n",
    "        '''\n",
    "        \n",
    "        if ttype == 'ne':\n",
    "            \n",
    "            no_gold_var = pd.read_csv('coref/ne_vars/nogold_var_ne', delimiter = '\\t')\n",
    "            gold_var = pd.read_csv('coref/ne_vars/gold_var_ne', delimiter = '\\t')\n",
    "            ids_nogold = pd.read_csv('coref/ne_vars/ids_ne_nogold', delimiter = '\\t')\n",
    "            ids_gold = pd.read_csv('coref/ne_vars/ids_ne_gold', delimiter = '\\t')\n",
    "            \n",
    "            no_gold_dummies, gold_dummies = self.fix_df(no_gold_var, gold_var)\n",
    "            \n",
    "            nogold = mod.predict(no_gold_dummies)\n",
    "            gold = mod.predict(gold_dummies)\n",
    "            \n",
    "            nogold = mod.predict_proba(no_gold_dummies)\n",
    "            gold = mod.predict_proba(gold_dummies)\n",
    "            \n",
    "            print(nogold)\n",
    "#             self.merge_ml(nogold, ids_nogold, gold=True)\n",
    "#             self.merge_ml(gold, ids_gold, gold=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        elif ttype == 'noun':\n",
    "            \n",
    "            no_gold_var = pd.read_csv('coref/noun_vars/nogold_var_noun', delimiter = '\\t')\n",
    "            gold_var = pd.read_csv('coref/noun_vars/gold_var_noun', delimiter = '\\t')\n",
    "            \n",
    "            no_gold_dummies, gold_dummies = self.fix_df(no_gold_var, gold_var)\n",
    "            \n",
    "            nogold = mod.predict(no_gold_var)\n",
    "            gold = mod.predict(gold_var)\n",
    "            \n",
    "        elif ttype == 'pron':\n",
    "            \n",
    "            no_gold_var = pd.read_csv('coref/pron_vars/nogold_var_pron', delimiter = '\\t')\n",
    "            gold_var = pd.read_csv('coref/pron_vars/gold_var_pron', delimiter = '\\t')\n",
    "            \n",
    "            no_gold_dummies, gold_dummies = self.fix_df(no_gold_var, gold_var)\n",
    "            \n",
    "            nogold = mod.predict(no_gold_var)\n",
    "            gold = mod.predict(old_var)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         self, mens, men_dict, manual, morph_merge, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'coref/ne_vars/train_var_ne' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5cf1d15fc82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnemodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ne'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mexample2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnemodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ne'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c32756958a86>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, ttype)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mttype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ne'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m             \u001b[0mtrain_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coref/ne_vars/train_var_ne'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coref/ne_vars/answers_ne'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/diploma/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/diploma/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/diploma/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/diploma/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/diploma/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'coref/ne_vars/train_var_ne' does not exist"
     ]
    }
   ],
   "source": [
    "var_list = ['genderm', 'animacym', 'numberm', 'headm', 'partialheadm', 'sentdist', \\\n",
    "           'nsubjant', 'detant', 'nsubjmen', 'detmen', 'nar_match', 'antecedenttype', 'NEtype_match', \\\n",
    "           'person_match', 'namepart', 'clustagree', 'containnum', 'namepartref', 'deprolemen', 'deproleant', \\\n",
    "           'deprolecomb', 'samesent','ptypemen', 'w2v_sim', 'wnet_syn', 'shiftdist']\n",
    "\n",
    "# 'sentinclust', 'clustlen', \\\n",
    "#            'clustpartial', 'clustw2v_sim', 'clustwnet_syn'] possible additions\n",
    "\n",
    "\n",
    "\n",
    "example2 = Coreftrain()\n",
    "\n",
    "example2.prepdf()\n",
    "\n",
    "# w2vmod = KeyedVectors.load_word2vec_format('ruwikiruscorpora_0_300_20.bin.gz', binary=True, encoding='utf8')\n",
    "\n",
    "# example2.create_vars(var_list, 'ne', w2vmod, train_per=.8, train_new = True) # first run\n",
    "\n",
    "\n",
    "nemodel, cols = example2.train('ne')\n",
    "\n",
    "example2.pipe(nemodel, 'ne', cols)\n",
    "\n",
    "# example2.pair()\n",
    "\n",
    "\n",
    "# example2.create_vars(var_list, 'noun', train_per=.8) # second run\n",
    "\n",
    "# nounmodel = example2.train('noun')\n",
    "\n",
    "# example2.pipe(nounmodel, 'noun')\n",
    "\n",
    "# example2.pair()\n",
    "\n",
    "\n",
    "# example2.create_vars(var_list, 'pron', train_per=.8) # third run\n",
    "\n",
    "# pronmodel = example2.train('pron')\n",
    "\n",
    "# example2.pipe(pronmodel, 'pron')\n",
    "\n",
    "# example2.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
